import thesis.experiment_data
import dopamine.jax.networks
import dopamine.replay_memory.circular_replay_buffer
import thesis.jax.agents.dqv_agent
import dopamine.jax.agents.dqn.dqn_agent
import dopamine.discrete_domains.gym_lib

# experiment config, online
ExperimentData.seed = 0
# ExperimentData.checkpoint_dir = "/home/xqz-u/uni/fourthYear/bsc-thesis/dopamine/thesis/tests/checkpoints"
# ExperimentData.checkpoint_iterations = ["46", "47"]
ExperimentData.stack_size = %gym_lib.CARTPOLE_STACK_SIZE
ExperimentData.min_replay_history = 500
ExperimentData.target_update_period = 100

ClassicControlDNNetwork.min_vals = %jax_networks.CARTPOLE_MIN_VALS
ClassicControlDNNetwork.max_vals = %jax_networks.CARTPOLE_MAX_VALS

# agent(s)
JaxDQVAgent.state_shape = %gym_lib.CARTPOLE_OBSERVATION_SHAPE
JaxDQVAgent.num_actions = 2
JaxDQVAgent.exp_data = @ExperimentData()
JaxDQVAgent.V_network = @ClassicControlDNNetwork
JaxDQVAgent.Q_network = @ClassicControlDNNetwork

JaxDQNAgent.observation_shape = %gym_lib.CARTPOLE_OBSERVATION_SHAPE
JaxDQNAgent.stack_size = %gym_lib.CARTPOLE_STACK_SIZE
JaxDQNAgent.network = @networks.ClassicControlDQNNetwork
JaxDQNAgent.num_actions = 2

# agent's NNs
# build_networks.V_features = (10,)
# build_networks.Q_features = (12,)

# memory stuff
# OfflineOutOfGraphReplayBuffer.observation_dtype = %jax_networks.CARTPOLE_OBSERVATION_DTYPE
OutOfGraphReplayBuffer.observation_dtype = %jax_networks.CARTPOLE_OBSERVATION_DTYPE
OutOfGraphReplayBuffer.replay_capacity = 50000
OutOfGraphReplayBuffer.batch_size = 128
