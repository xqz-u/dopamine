import dopamine.discrete_domains.gym_lib
import dopamine.jax.networks
import dopamine.replay_memory.circular_replay_buffer
# changed
import thesis.dqn_agent_replay
import thesis.replay_dumps

OutOfGraphReplayBuffer.replay_capacity = 50000
OutOfGraphReplayBuffer.batch_size = 128

JaxDQNAgent.observation_shape = %gym_lib.CARTPOLE_OBSERVATION_SHAPE
JaxDQNAgent.observation_dtype = %jax_networks.CARTPOLE_OBSERVATION_DTYPE
JaxDQNAgent.stack_size = %gym_lib.CARTPOLE_STACK_SIZE
JaxDQNAgent.network = @networks.ClassicControlDQNNetwork
JaxDQNAgent.min_replay_history = 500
JaxDQNAgent.target_update_period = 100

# changed NOTE probably epsilon_fn does not need module name since it would
# override the definition in dopamine/agents/dqn/dqn_agent?!

cartpole_dqn_buf_loader.buf = @OutOfGraphReplayBuffer()
JaxDQNAgent.num_actions = 2
# JaxDQNAgent.num_actions = %replay_dumps.CARTPOLE_N_ACTIONS
JaxDQNAgent.epsilon_fn = @identity_epsilon
JaxDQNAgent.replay_loader = @replay_dumps.cartpole_dqn_buf_loader

create_optimizer.learning_rate = 0.001
create_optimizer.eps = 3.125e-4

ClassicControlDQNNetwork.min_vals = %jax_networks.CARTPOLE_MIN_VALS
ClassicControlDQNNetwork.max_vals = %jax_networks.CARTPOLE_MAX_VALS